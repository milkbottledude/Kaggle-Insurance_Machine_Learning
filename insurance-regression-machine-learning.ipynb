{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec6d0b5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-18T09:25:00.717074Z",
     "iopub.status.busy": "2024-12-18T09:25:00.716683Z",
     "iopub.status.idle": "2024-12-18T09:25:01.537788Z",
     "shell.execute_reply": "2024-12-18T09:25:01.536582Z"
    },
    "papermill": {
     "duration": 0.829514,
     "end_time": "2024-12-18T09:25:01.540274",
     "exception": false,
     "start_time": "2024-12-18T09:25:00.710760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s4e12/sample_submission.csv\n",
      "/kaggle/input/playground-series-s4e12/train.csv\n",
      "/kaggle/input/playground-series-s4e12/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452b430",
   "metadata": {
    "papermill": {
     "duration": 0.003437,
     "end_time": "2024-12-18T09:25:01.547738",
     "exception": false,
     "start_time": "2024-12-18T09:25:01.544301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1) Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76225727",
   "metadata": {
    "papermill": {
     "duration": 0.003308,
     "end_time": "2024-12-18T09:25:01.554716",
     "exception": false,
     "start_time": "2024-12-18T09:25:01.551408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## configuring training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa29f1c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:25:01.563854Z",
     "iopub.status.busy": "2024-12-18T09:25:01.562952Z",
     "iopub.status.idle": "2024-12-18T09:25:21.651082Z",
     "shell.execute_reply": "2024-12-18T09:25:21.649908Z"
    },
    "papermill": {
     "duration": 20.095846,
     "end_time": "2024-12-18T09:25:21.653968",
     "exception": false,
     "start_time": "2024-12-18T09:25:01.558122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fillNaN [mean] complete\n",
      "fillNaN [median] complete\n",
      "fillNaN [mode] complete\n",
      "1200000\n",
      "800000\n",
      "960000\n",
      "                                  0       1\n",
      "Age                              48      48\n",
      "Gender                            2       2\n",
      "Annual Income                 88593   80716\n",
      "Number of Dependents              6       6\n",
      "Health Score                 532658  388703\n",
      "Previous Claims                  10      10\n",
      "Vehicle Age                      20      20\n",
      "Credit Score                    550     550\n",
      "Insurance Duration                9       9\n",
      "Customer Feedback                 3       3\n",
      "Smoking Status                    2       2\n",
      "start year                        6       6\n",
      "Marital Status_Divorced           2       2\n",
      "Marital Status_Married            2       2\n",
      "Marital Status_Single             2       2\n",
      "Education Level_Bachelor's        2       2\n",
      "Education Level_High School       2       2\n",
      "Education Level_Master's          2       2\n",
      "Education Level_PhD               2       2\n",
      "Occupation_Employed               2       2\n",
      "Occupation_Self-Employed          2       2\n",
      "Occupation_Unemployed             2       2\n",
      "Location_Rural                    2       2\n",
      "Location_Suburban                 2       2\n",
      "Location_Urban                    2       2\n",
      "Policy Type_Basic                 2       2\n",
      "Policy Type_Comprehensive         2       2\n",
      "Policy Type_Premium               2       2\n",
      "Exercise Frequency_Daily          2       2\n",
      "Exercise Frequency_Monthly        2       2\n",
      "Exercise Frequency_Rarely         2       2\n",
      "Exercise Frequency_Weekly         2       2\n",
      "Property Type_Apartment           2       2\n",
      "Property Type_Condo               2       2\n",
      "Property Type_House               2       2\n",
      "start month_Apr                   2       2\n",
      "start month_Aug                   2       2\n",
      "start month_Dec                   2       2\n",
      "start month_Feb                   2       2\n",
      "start month_Jan                   2       2\n",
      "start month_Jul                   2       2\n",
      "start month_Jun                   2       2\n",
      "start month_Mar                   2       2\n",
      "start month_May                   2       2\n",
      "start month_Nov                   2       2\n",
      "start month_Oct                   2       2\n",
      "start month_Sep                   2       2\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/playground-series-s4e12/train.csv')\n",
    "y = train_data['Premium Amount']\n",
    "train_data = train_data.drop(['id', 'Premium Amount'], axis=1)\n",
    "\n",
    "test_data = pd.read_csv('/kaggle/input/playground-series-s4e12/test.csv')\n",
    "test_ids = test_data['id']\n",
    "test_data = test_data.drop(['id'], axis=1)\n",
    "\n",
    "# function to check for NaN values in a specified column\n",
    "def checknan(colname):\n",
    "    return train_data[train_data[colname].isna()]\n",
    "\n",
    "# function to fillna with either mean, median, 0, or another column\n",
    "def fillNaN(colnamelist, type, othercol=None, datasetlist=[train_data, test_data]):\n",
    "    if type == 'mean':\n",
    "        for dataset in datasetlist:\n",
    "            for colname in colnamelist:\n",
    "                dataset.fillna({colname: train_data[colname].mean()}, inplace=True) # Version14: adding test_data to the fillNaN function\n",
    "    elif type == 'median':\n",
    "        for dataset in datasetlist:\n",
    "            for colname in colnamelist:\n",
    "                dataset.fillna({colname: train_data[colname].median()}, inplace=True)\n",
    "    elif type == 'mode':\n",
    "        for dataset in datasetlist:\n",
    "            for colname in colnamelist:\n",
    "                dataset.fillna({colname: train_data[colname].mode()[0]}, inplace=True)\n",
    "    elif type == 0:\n",
    "        for dataset in datasetlist:\n",
    "            for colname in colnamelist:\n",
    "                dataset.fillna({colname: 0}, inplace=True)\n",
    "    elif type == 'othercol':\n",
    "        for dataset in datasetlist:\n",
    "            for colname in colnamelist:\n",
    "                dataset.fillna({colname: train_data[othercol]}, inplace=True)\n",
    "    print(f'fillNaN [{type}] complete')\n",
    "\n",
    "# nan_cols = train_data.columns[train_data.isna().any()]\n",
    "# for col in nan_cols:\n",
    "#     print(f'- {col}')\n",
    "\n",
    "meanfillna = ['Age', 'Number of Dependents', 'Health Score']\n",
    "medianfillna = ['Annual Income', 'Vehicle Age', 'Credit Score', 'Insurance Duration']\n",
    "modefillna = ['Marital Status', 'Occupation', 'Previous Claims', 'Customer Feedback']\n",
    "\n",
    "fillNaN(meanfillna, 'mean') # fillna for columns using mean\n",
    "fillNaN(medianfillna, 'median') # fillna for columns using median\n",
    "fillNaN(modefillna, 'mode') # fillna for columns using mode\n",
    "\n",
    "# processing the values in the 'Policy Start Date', 'Gender', 'Customer Feedback', and 'Smoking Status' columns\n",
    "# starting with 'Policy Start Date'\n",
    "train_data['Policy Start Date'] = pd.to_datetime(train_data['Policy Start Date'])\n",
    "train_data['start year'] = train_data['Policy Start Date'].dt.year\n",
    "train_data['start month'] = train_data['Policy Start Date'].dt.month\n",
    "train_data = train_data.drop(['Policy Start Date'], axis=1)\n",
    "\n",
    "test_data['Policy Start Date'] = pd.to_datetime(test_data['Policy Start Date'])\n",
    "test_data['start year'] = test_data['Policy Start Date'].dt.year\n",
    "test_data['start month'] = test_data['Policy Start Date'].dt.month\n",
    "test_data = test_data.drop(['Policy Start Date'], axis=1)\n",
    "\n",
    "monthmap = {\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec'\n",
    "}\n",
    "\n",
    "train_data['start month'] = train_data['start month'].map(monthmap)\n",
    "test_data['start month'] = test_data['start month'].map(monthmap)\n",
    "\n",
    "# on to 'Gender'\n",
    "gendermap = {'Male': 1, 'Female': 0}\n",
    "train_data['Gender'] = train_data['Gender'].map(gendermap)\n",
    "test_data['Gender'] = test_data['Gender'].map(gendermap)\n",
    "\n",
    "# Customer Feedback\n",
    "feedbackmap = {'Poor': 1, 'Average': 2, 'Good': 3}\n",
    "train_data['Customer Feedback'] = train_data['Customer Feedback'].map(feedbackmap)\n",
    "test_data['Customer Feedback'] = test_data['Customer Feedback'].map(feedbackmap)\n",
    "\n",
    "# Smoking Status\n",
    "smokingmap = {'Yes': 1, 'No': 0}\n",
    "train_data['Smoking Status'] = train_data['Smoking Status'].map(smokingmap)\n",
    "test_data['Smoking Status'] = test_data['Smoking Status'].map(smokingmap)\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "# prepping data to go into machine learning model\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "# converting boolean values to int\n",
    "bool_columns = train_data.select_dtypes(include=['bool']).columns\n",
    "train_data[bool_columns] = train_data[bool_columns].astype(int)\n",
    "test_data[bool_columns] = test_data[bool_columns].astype(int)\n",
    "\n",
    "# splitting train_data into train and mock test data\n",
    "X_train, X_mocktest, y_train, y_mocktest = train_test_split(train_data, y, test_size=0.2, random_state=0)\n",
    "print(len(X_train))\n",
    "\n",
    "print(pd.concat([train_data.nunique(), test_data.nunique()], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c848e1",
   "metadata": {
    "papermill": {
     "duration": 0.003798,
     "end_time": "2024-12-18T09:25:21.661996",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.658198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2) Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e123c8",
   "metadata": {
    "papermill": {
     "duration": 0.00366,
     "end_time": "2024-12-18T09:25:21.669640",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.665980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14758e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:25:21.679135Z",
     "iopub.status.busy": "2024-12-18T09:25:21.678621Z",
     "iopub.status.idle": "2024-12-18T09:25:21.684140Z",
     "shell.execute_reply": "2024-12-18T09:25:21.683147Z"
    },
    "papermill": {
     "duration": 0.012652,
     "end_time": "2024-12-18T09:25:21.686152",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.673500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error as msle\n",
    "\n",
    "# lrmodel = LinearRegression()\n",
    "# lrmodel.fit(X_train, y_train)\n",
    "# mockpreds = lrmodel.predict(X_mocktest)\n",
    "\n",
    "def rmsle(actual_y, predicted_y):\n",
    "    return np.sqrt(msle(actual_y, predicted_y))\n",
    "\n",
    "# print(rmsle(y_mocktest, mockpreds))\n",
    "\n",
    "# # # deleting objects after use to prevent ram overload\n",
    "# # del mockpreds, X_train, X_mocktest, y_train, y_mocktest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87391f1f",
   "metadata": {
    "papermill": {
     "duration": 0.003868,
     "end_time": "2024-12-18T09:25:21.694168",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.690300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42b54dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:25:21.703897Z",
     "iopub.status.busy": "2024-12-18T09:25:21.703503Z",
     "iopub.status.idle": "2024-12-18T09:25:21.708026Z",
     "shell.execute_reply": "2024-12-18T09:25:21.707057Z"
    },
    "papermill": {
     "duration": 0.012088,
     "end_time": "2024-12-18T09:25:21.710230",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.698142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# dtrmodel = DecisionTreeRegressor(random_state=0)\n",
    "# dtrmodel.fit(X_train, y_train)\n",
    "# mockpreds = dtrmodel.predict(X_mocktest)\n",
    "# print(rmsle(y_mocktest, mockpreds))\n",
    "\n",
    "# # # deleting objects after use to prevent ram overload\n",
    "# # del mockpreds, X_train, X_mocktest, y_train, y_mocktest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52099f",
   "metadata": {
    "papermill": {
     "duration": 0.003811,
     "end_time": "2024-12-18T09:25:21.718312",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.714501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb9c553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:25:21.729363Z",
     "iopub.status.busy": "2024-12-18T09:25:21.728312Z",
     "iopub.status.idle": "2024-12-18T09:25:21.732982Z",
     "shell.execute_reply": "2024-12-18T09:25:21.732009Z"
    },
    "papermill": {
     "duration": 0.011907,
     "end_time": "2024-12-18T09:25:21.735010",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.723103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# rfrmodel = RandomForestRegressor(random_state=0)\n",
    "# rfrmodel.fit(X_train, y_train)\n",
    "# mockpreds = rfrmodel.predict(X_mocktest)\n",
    "# print(rmsle(y_mocktest, mockpreds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec632d4b",
   "metadata": {
    "papermill": {
     "duration": 0.003675,
     "end_time": "2024-12-18T09:25:21.742644",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.738969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Deep Neural Network with TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d546b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:25:21.752419Z",
     "iopub.status.busy": "2024-12-18T09:25:21.752038Z",
     "iopub.status.idle": "2024-12-18T09:28:05.919807Z",
     "shell.execute_reply": "2024-12-18T09:28:05.918475Z"
    },
    "papermill": {
     "duration": 164.175952,
     "end_time": "2024-12-18T09:28:05.922439",
     "exception": false,
     "start_time": "2024-12-18T09:25:21.746487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 2.9415 - val_loss: 1.1915\n",
      "Epoch 2/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1889 - val_loss: 1.1866\n",
      "Epoch 3/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1849 - val_loss: 1.1823\n",
      "Epoch 4/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1818 - val_loss: 1.1809\n",
      "Epoch 5/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1807 - val_loss: 1.1797\n",
      "Epoch 6/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1789 - val_loss: 1.1765\n",
      "Epoch 7/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1757 - val_loss: 1.1735\n",
      "Epoch 8/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1731 - val_loss: 1.1714\n",
      "Epoch 9/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1713 - val_loss: 1.1700\n",
      "Epoch 10/10\n",
      "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 1.1700 - val_loss: 1.1689\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "# setting constant random_seed, similar to random_state in previous models\n",
    "keras.utils.set_random_seed(0)\n",
    "\n",
    "# Versmaking sequential api model\n",
    "seqmodel = tf.keras.Sequential()\n",
    "# start off small with 3 layers, including the input and output layers\n",
    "seqmodel.add(tf.keras.layers.Input(shape=(47,)))\n",
    "seqmodel.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "seqmodel.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "seqmodel.add(tf.keras.layers.Dense(1))\n",
    "seqmodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='msle'\n",
    "    # metrics=['mae', 'RootMeanSquaredError']\n",
    ")\n",
    "\n",
    "# converting dataframes to arrays\n",
    "X_train = X_train.to_numpy()\n",
    "X_mocktest = X_mocktest.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_mocktest = y_mocktest.to_numpy()\n",
    "\n",
    "# Version 28: minmax scaling data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_mocktest = scaler.fit_transform(X_mocktest)\n",
    "\n",
    "# training the model\n",
    "batchsize = 100\n",
    "epochnumber = 10\n",
    "history = seqmodel.fit(X_train, y_train, epochs=epochnumber, batch_size=batchsize, validation_data=(X_mocktest, y_mocktest))\n",
    "# seqmodel.evaluate(X_mocktest, y_mocktest, batch_size=batchsize)\n",
    "\n",
    "# plotting RMSLE against epoch number\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_RMSLE = history.history['loss'] # accessing list of training losses\n",
    "val_RMSLE = history.history['val_loss'] # accessing list of validation losses\n",
    "# making list of epochs for x-axis of graph\n",
    "epochlist = []\n",
    "for e in range(1, epochnumber+1):\n",
    "    epochlist.append(e)\n",
    "# plotting graph\n",
    "plt.plot(epochlist, train_RMSLE, color='blue', label='train_loss')\n",
    "plt.plot(epochlist, val_RMSLE, color='red', label='val_loss')\n",
    "plt.ylim(1.1, 1.2)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss against epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11089a33",
   "metadata": {
    "papermill": {
     "duration": 0.1528,
     "end_time": "2024-12-18T09:28:06.272967",
     "exception": false,
     "start_time": "2024-12-18T09:28:06.120167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission (for sequential nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1b0d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T09:28:06.625755Z",
     "iopub.status.busy": "2024-12-18T09:28:06.624914Z",
     "iopub.status.idle": "2024-12-18T10:34:07.132709Z",
     "shell.execute_reply": "2024-12-18T10:34:07.131307Z"
    },
    "papermill": {
     "duration": 3960.667206,
     "end_time": "2024-12-18T10:34:07.135141",
     "exception": false,
     "start_time": "2024-12-18T09:28:06.467935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1665 - val_loss: 1.1530\n",
      "Epoch 2/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1655 - val_loss: 1.1521\n",
      "Epoch 3/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1646 - val_loss: 1.1511\n",
      "Epoch 4/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1637 - val_loss: 1.1500\n",
      "Epoch 5/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1625 - val_loss: 1.1487\n",
      "Epoch 6/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1612 - val_loss: 1.1475\n",
      "Epoch 7/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1601 - val_loss: 1.1462\n",
      "Epoch 8/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1589 - val_loss: 1.1453\n",
      "Epoch 9/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1579 - val_loss: 1.1443\n",
      "Epoch 10/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1570 - val_loss: 1.1435\n",
      "Epoch 11/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1562 - val_loss: 1.1429\n",
      "Epoch 12/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1555 - val_loss: 1.1423\n",
      "Epoch 13/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1547 - val_loss: 1.1416\n",
      "Epoch 14/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1541 - val_loss: 1.1406\n",
      "Epoch 15/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1535 - val_loss: 1.1403\n",
      "Epoch 16/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1529 - val_loss: 1.1399\n",
      "Epoch 17/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1524 - val_loss: 1.1391\n",
      "Epoch 18/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1518 - val_loss: 1.1388\n",
      "Epoch 19/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1513 - val_loss: 1.1384\n",
      "Epoch 20/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1508 - val_loss: 1.1380\n",
      "Epoch 21/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1503 - val_loss: 1.1376\n",
      "Epoch 22/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1500 - val_loss: 1.1373\n",
      "Epoch 23/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1496 - val_loss: 1.1373\n",
      "Epoch 24/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1494 - val_loss: 1.1369\n",
      "Epoch 25/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1491 - val_loss: 1.1367\n",
      "Epoch 26/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1488 - val_loss: 1.1365\n",
      "Epoch 27/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1485 - val_loss: 1.1356\n",
      "Epoch 28/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1480 - val_loss: 1.1353\n",
      "Epoch 29/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1476 - val_loss: 1.1351\n",
      "Epoch 30/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1472 - val_loss: 1.1347\n",
      "Epoch 31/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1468 - val_loss: 1.1343\n",
      "Epoch 32/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1465 - val_loss: 1.1343\n",
      "Epoch 33/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1461 - val_loss: 1.1338\n",
      "Epoch 34/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1459 - val_loss: 1.1335\n",
      "Epoch 35/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 1.1457 - val_loss: 1.1333\n",
      "Epoch 36/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1454 - val_loss: 1.1331\n",
      "Epoch 37/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1452 - val_loss: 1.1329\n",
      "Epoch 38/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1451 - val_loss: 1.1328\n",
      "Epoch 39/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1450 - val_loss: 1.1327\n",
      "Epoch 40/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1448 - val_loss: 1.1326\n",
      "Epoch 41/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1446 - val_loss: 1.1324\n",
      "Epoch 42/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1445 - val_loss: 1.1322\n",
      "Epoch 43/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1444 - val_loss: 1.1322\n",
      "Epoch 44/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1443 - val_loss: 1.1322\n",
      "Epoch 45/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1442 - val_loss: 1.1322\n",
      "Epoch 46/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1441 - val_loss: 1.1321\n",
      "Epoch 47/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1440 - val_loss: 1.1321\n",
      "Epoch 48/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1439 - val_loss: 1.1320\n",
      "Epoch 49/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1439 - val_loss: 1.1320\n",
      "Epoch 50/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1437 - val_loss: 1.1321\n",
      "Epoch 51/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1437 - val_loss: 1.1321\n",
      "Epoch 52/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1435 - val_loss: 1.1318\n",
      "Epoch 53/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1435 - val_loss: 1.1319\n",
      "Epoch 54/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1434 - val_loss: 1.1319\n",
      "Epoch 55/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1433 - val_loss: 1.1317\n",
      "Epoch 56/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1432 - val_loss: 1.1317\n",
      "Epoch 57/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1431 - val_loss: 1.1318\n",
      "Epoch 58/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1430 - val_loss: 1.1316\n",
      "Epoch 59/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1430 - val_loss: 1.1316\n",
      "Epoch 60/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1429 - val_loss: 1.1316\n",
      "Epoch 61/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1428 - val_loss: 1.1316\n",
      "Epoch 62/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1427 - val_loss: 1.1316\n",
      "Epoch 63/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1426 - val_loss: 1.1318\n",
      "Epoch 64/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1425 - val_loss: 1.1317\n",
      "Epoch 65/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1423 - val_loss: 1.1316\n",
      "Epoch 66/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1423 - val_loss: 1.1317\n",
      "Epoch 67/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1422 - val_loss: 1.1316\n",
      "Epoch 68/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1421 - val_loss: 1.1314\n",
      "Epoch 69/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1419 - val_loss: 1.1313\n",
      "Epoch 70/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1419 - val_loss: 1.1310\n",
      "Epoch 71/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1417 - val_loss: 1.1311\n",
      "Epoch 72/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1415 - val_loss: 1.1309\n",
      "Epoch 73/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1414 - val_loss: 1.1309\n",
      "Epoch 74/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1413 - val_loss: 1.1308\n",
      "Epoch 75/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1411 - val_loss: 1.1306\n",
      "Epoch 76/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1409 - val_loss: 1.1305\n",
      "Epoch 77/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1408 - val_loss: 1.1302\n",
      "Epoch 78/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1407 - val_loss: 1.1302\n",
      "Epoch 79/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1405 - val_loss: 1.1299\n",
      "Epoch 80/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1403 - val_loss: 1.1301\n",
      "Epoch 81/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1402 - val_loss: 1.1295\n",
      "Epoch 82/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1401 - val_loss: 1.1297\n",
      "Epoch 83/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1399 - val_loss: 1.1297\n",
      "Epoch 84/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1398 - val_loss: 1.1296\n",
      "Epoch 85/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1396 - val_loss: 1.1292\n",
      "Epoch 86/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1395 - val_loss: 1.1293\n",
      "Epoch 87/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1393 - val_loss: 1.1291\n",
      "Epoch 88/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1393 - val_loss: 1.1291\n",
      "Epoch 89/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1392 - val_loss: 1.1292\n",
      "Epoch 90/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1391 - val_loss: 1.1290\n",
      "Epoch 91/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1389 - val_loss: 1.1290\n",
      "Epoch 92/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1389 - val_loss: 1.1289\n",
      "Epoch 93/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1388 - val_loss: 1.1288\n",
      "Epoch 94/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1387 - val_loss: 1.1289\n",
      "Epoch 95/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1386 - val_loss: 1.1287\n",
      "Epoch 96/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1385 - val_loss: 1.1285\n",
      "Epoch 97/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1384 - val_loss: 1.1285\n",
      "Epoch 98/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1383 - val_loss: 1.1283\n",
      "Epoch 99/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1383 - val_loss: 1.1285\n",
      "Epoch 100/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1382 - val_loss: 1.1285\n",
      "Epoch 101/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1382 - val_loss: 1.1285\n",
      "Epoch 102/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1381 - val_loss: 1.1285\n",
      "Epoch 103/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1380 - val_loss: 1.1282\n",
      "Epoch 104/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1380 - val_loss: 1.1282\n",
      "Epoch 105/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1379 - val_loss: 1.1283\n",
      "Epoch 106/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1378 - val_loss: 1.1279\n",
      "Epoch 107/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1378 - val_loss: 1.1282\n",
      "Epoch 108/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1377 - val_loss: 1.1279\n",
      "Epoch 109/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1377 - val_loss: 1.1284\n",
      "Epoch 110/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1377 - val_loss: 1.1281\n",
      "Epoch 111/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1375 - val_loss: 1.1280\n",
      "Epoch 112/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1376 - val_loss: 1.1280\n",
      "Epoch 113/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1375 - val_loss: 1.1277\n",
      "Epoch 114/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1374 - val_loss: 1.1280\n",
      "Epoch 115/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1375 - val_loss: 1.1281\n",
      "Epoch 116/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1374 - val_loss: 1.1278\n",
      "Epoch 117/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1373 - val_loss: 1.1280\n",
      "Epoch 118/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1373 - val_loss: 1.1278\n",
      "Epoch 119/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1373 - val_loss: 1.1278\n",
      "Epoch 120/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1371 - val_loss: 1.1280\n",
      "Epoch 121/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1371 - val_loss: 1.1278\n",
      "Epoch 122/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1372 - val_loss: 1.1280\n",
      "Epoch 123/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1371 - val_loss: 1.1277\n",
      "Epoch 124/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1370 - val_loss: 1.1280\n",
      "Epoch 125/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1370 - val_loss: 1.1276\n",
      "Epoch 126/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1369 - val_loss: 1.1276\n",
      "Epoch 127/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1368 - val_loss: 1.1279\n",
      "Epoch 128/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1368 - val_loss: 1.1280\n",
      "Epoch 129/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1368 - val_loss: 1.1274\n",
      "Epoch 130/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1368 - val_loss: 1.1277\n",
      "Epoch 131/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1368 - val_loss: 1.1279\n",
      "Epoch 132/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1367 - val_loss: 1.1278\n",
      "Epoch 133/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1368 - val_loss: 1.1277\n",
      "Epoch 134/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1367 - val_loss: 1.1276\n",
      "Epoch 135/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1366 - val_loss: 1.1275\n",
      "Epoch 136/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1366 - val_loss: 1.1274\n",
      "Epoch 137/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1365 - val_loss: 1.1276\n",
      "Epoch 138/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1364 - val_loss: 1.1275\n",
      "Epoch 139/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1364 - val_loss: 1.1276\n",
      "Epoch 140/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1364 - val_loss: 1.1279\n",
      "Epoch 141/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1363 - val_loss: 1.1278\n",
      "Epoch 142/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1364 - val_loss: 1.1279\n",
      "Epoch 143/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1363 - val_loss: 1.1276\n",
      "Epoch 144/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1364 - val_loss: 1.1278\n",
      "Epoch 145/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1362 - val_loss: 1.1275\n",
      "Epoch 146/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1363 - val_loss: 1.1279\n",
      "Epoch 147/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1361 - val_loss: 1.1276\n",
      "Epoch 148/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1362 - val_loss: 1.1278\n",
      "Epoch 149/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1361 - val_loss: 1.1276\n",
      "Epoch 150/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1361 - val_loss: 1.1276\n",
      "Epoch 151/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1361 - val_loss: 1.1278\n",
      "Epoch 152/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1361 - val_loss: 1.1279\n",
      "Epoch 153/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1360 - val_loss: 1.1278\n",
      "Epoch 154/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1360 - val_loss: 1.1277\n",
      "Epoch 155/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1360 - val_loss: 1.1276\n",
      "Epoch 156/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1359 - val_loss: 1.1275\n",
      "Epoch 157/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1360 - val_loss: 1.1277\n",
      "Epoch 158/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1359 - val_loss: 1.1276\n",
      "Epoch 159/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1359 - val_loss: 1.1277\n",
      "Epoch 160/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1358 - val_loss: 1.1277\n",
      "Epoch 161/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1358 - val_loss: 1.1279\n",
      "Epoch 162/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1358 - val_loss: 1.1277\n",
      "Epoch 163/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1358 - val_loss: 1.1275\n",
      "Epoch 164/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1357 - val_loss: 1.1277\n",
      "Epoch 165/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1357 - val_loss: 1.1278\n",
      "Epoch 166/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1358 - val_loss: 1.1277\n",
      "Epoch 167/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1357 - val_loss: 1.1275\n",
      "Epoch 168/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1356 - val_loss: 1.1277\n",
      "Epoch 169/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1356 - val_loss: 1.1278\n",
      "Epoch 170/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1355 - val_loss: 1.1277\n",
      "Epoch 171/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1355 - val_loss: 1.1277\n",
      "Epoch 172/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1355 - val_loss: 1.1273\n",
      "Epoch 173/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1354 - val_loss: 1.1277\n",
      "Epoch 174/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1354 - val_loss: 1.1275\n",
      "Epoch 175/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1354 - val_loss: 1.1276\n",
      "Epoch 176/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1353 - val_loss: 1.1276\n",
      "Epoch 177/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1352 - val_loss: 1.1274\n",
      "Epoch 178/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1352 - val_loss: 1.1276\n",
      "Epoch 179/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1352 - val_loss: 1.1277\n",
      "Epoch 180/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1352 - val_loss: 1.1275\n",
      "Epoch 181/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1351 - val_loss: 1.1273\n",
      "Epoch 182/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1ms/step - loss: 1.1350 - val_loss: 1.1271\n",
      "Epoch 183/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1350 - val_loss: 1.1271\n",
      "Epoch 184/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1350 - val_loss: 1.1271\n",
      "Epoch 185/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1349 - val_loss: 1.1271\n",
      "Epoch 186/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1349 - val_loss: 1.1268\n",
      "Epoch 187/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1348 - val_loss: 1.1268\n",
      "Epoch 188/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1348 - val_loss: 1.1269\n",
      "Epoch 189/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1349 - val_loss: 1.1272\n",
      "Epoch 190/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1349 - val_loss: 1.1270\n",
      "Epoch 191/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1348 - val_loss: 1.1269\n",
      "Epoch 192/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1347 - val_loss: 1.1270\n",
      "Epoch 193/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1348 - val_loss: 1.1270\n",
      "Epoch 194/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1347 - val_loss: 1.1270\n",
      "Epoch 195/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1347 - val_loss: 1.1269\n",
      "Epoch 196/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1346 - val_loss: 1.1268\n",
      "Epoch 197/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1345 - val_loss: 1.1268\n",
      "Epoch 198/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1345 - val_loss: 1.1270\n",
      "Epoch 199/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1345 - val_loss: 1.1270\n",
      "Epoch 200/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1345 - val_loss: 1.1264\n",
      "Epoch 201/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1345 - val_loss: 1.1266\n",
      "Epoch 202/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1344 - val_loss: 1.1267\n",
      "Epoch 203/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1343 - val_loss: 1.1269\n",
      "Epoch 204/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1342 - val_loss: 1.1268\n",
      "Epoch 205/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1341 - val_loss: 1.1263\n",
      "Epoch 206/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1340 - val_loss: 1.1265\n",
      "Epoch 207/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1341 - val_loss: 1.1264\n",
      "Epoch 208/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1339 - val_loss: 1.1263\n",
      "Epoch 209/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1338 - val_loss: 1.1261\n",
      "Epoch 210/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1338 - val_loss: 1.1259\n",
      "Epoch 211/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1337 - val_loss: 1.1262\n",
      "Epoch 212/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1336 - val_loss: 1.1258\n",
      "Epoch 213/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1334 - val_loss: 1.1257\n",
      "Epoch 214/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1334 - val_loss: 1.1257\n",
      "Epoch 215/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1333 - val_loss: 1.1258\n",
      "Epoch 216/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1332 - val_loss: 1.1259\n",
      "Epoch 217/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1331 - val_loss: 1.1256\n",
      "Epoch 218/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1330 - val_loss: 1.1256\n",
      "Epoch 219/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1330 - val_loss: 1.1256\n",
      "Epoch 220/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1328 - val_loss: 1.1256\n",
      "Epoch 221/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1327 - val_loss: 1.1256\n",
      "Epoch 222/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1325 - val_loss: 1.1253\n",
      "Epoch 223/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1325 - val_loss: 1.1255\n",
      "Epoch 224/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1325 - val_loss: 1.1253\n",
      "Epoch 225/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1322 - val_loss: 1.1253\n",
      "Epoch 226/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1321 - val_loss: 1.1254\n",
      "Epoch 227/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1320 - val_loss: 1.1250\n",
      "Epoch 228/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1320 - val_loss: 1.1250\n",
      "Epoch 229/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1319 - val_loss: 1.1248\n",
      "Epoch 230/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1317 - val_loss: 1.1247\n",
      "Epoch 231/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1316 - val_loss: 1.1245\n",
      "Epoch 232/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1315 - val_loss: 1.1247\n",
      "Epoch 233/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1313 - val_loss: 1.1241\n",
      "Epoch 234/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1312 - val_loss: 1.1244\n",
      "Epoch 235/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1310 - val_loss: 1.1238\n",
      "Epoch 236/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1309 - val_loss: 1.1241\n",
      "Epoch 237/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1308 - val_loss: 1.1237\n",
      "Epoch 238/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1307 - val_loss: 1.1237\n",
      "Epoch 239/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1306 - val_loss: 1.1236\n",
      "Epoch 240/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1304 - val_loss: 1.1234\n",
      "Epoch 241/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1303 - val_loss: 1.1231\n",
      "Epoch 242/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1301 - val_loss: 1.1232\n",
      "Epoch 243/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1300 - val_loss: 1.1229\n",
      "Epoch 244/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1298 - val_loss: 1.1230\n",
      "Epoch 245/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1298 - val_loss: 1.1228\n",
      "Epoch 246/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1296 - val_loss: 1.1228\n",
      "Epoch 247/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1295 - val_loss: 1.1230\n",
      "Epoch 248/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1293 - val_loss: 1.1224\n",
      "Epoch 249/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 1.1292 - val_loss: 1.1220\n",
      "Epoch 250/250\n",
      "\u001b[1m11400/11400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - loss: 1.1290 - val_loss: 1.1221\n",
      "\u001b[1m8000/8000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "             id  Premium Amount\n",
      "0       1200000      628.315674\n",
      "1       1200001      791.096558\n",
      "2       1200002      777.275269\n",
      "3       1200003      720.636475\n",
      "4       1200004      740.577148\n",
      "...         ...             ...\n",
      "799995  1999995     1008.814819\n",
      "799996  1999996      740.332397\n",
      "799997  1999997      774.119385\n",
      "799998  1999998      750.353821\n",
      "799999  1999999      605.517395\n",
      "\n",
      "[800000 rows x 2 columns]\n",
      "success yahuu\n"
     ]
    }
   ],
   "source": [
    "# converting training df to np arrays\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "y = y.to_numpy()\n",
    "\n",
    "history2 = seqmodel.fit(train_data, y, epochs=250, batch_size=batchsize, validation_split=0.05)\n",
    "\n",
    "# # plotting val_data against epochs again\n",
    "# val_RMSLE2 = history2.history['val_loss']\n",
    "# plt.plot(epochlist, val_RMSLE2, color='purple', label='val_loss2')\n",
    "# plt.ylim(1.1, 1.2)\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.title('loss against epochs')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# prepping test_data for the model\n",
    "test_data = pd.get_dummies(test_data)\n",
    "test_data = scaler.fit_transform(test_data)\n",
    "\n",
    "preds = seqmodel.predict(test_data, batch_size=batchsize)\n",
    "\n",
    "# creating submission Dataframe\n",
    "preds = preds.flatten()\n",
    "output = pd.DataFrame({'id': test_ids, 'Premium Amount': preds})\n",
    "print(output)\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print('success yahuu')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10305135,
     "sourceId": 84896,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4155.872967,
   "end_time": "2024-12-18T10:34:13.920944",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-18T09:24:58.047977",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
